{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07c07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8278dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'lol_ranked_dataset/games.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236b9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to remove\n",
    "columns_to_remove = ['gameId', 'creationTime', 'seasonId']\n",
    "\n",
    "# Remove the columns using drop() method with axis=1\n",
    "df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f19dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a64e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a93ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension to identify columns to keep as numeric\n",
    "columns_to_keep_numeric = [col for col in df.columns if 'Kills' in col]\n",
    "\n",
    "# Convert all columns to object type except columns with 'kills' in their names\n",
    "df.loc[:, ~df.columns.isin(columns_to_keep_numeric)] = df.loc[:, ~df.columns.isin(columns_to_keep_numeric)].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907e1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2de1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only integer columns for analysis\n",
    "integer_columns = df.select_dtypes(include=['int64'])\n",
    "\n",
    "# Plot histograms for each column\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, col in enumerate(integer_columns.columns):\n",
    "    plt.subplot(5, 4, i + 1)  # Adjust subplot grid as per your number of columns\n",
    "    plt.hist(integer_columns[col], bins=20, edgecolor='black')\n",
    "    plt.title(col)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac93383",
   "metadata": {},
   "source": [
    "## Team 1 Stats\n",
    "\n",
    "### Tower Kills\n",
    "The distribution of tower kills in games shows:\n",
    "- **Peak**: Most games have a high number of tower kills, reaching a maximum of 11. These high values often correspond to one-sided wins.\n",
    "- **Minimum**: The lowest value is 0, indicating total defeat.\n",
    "- **In-Between**: There are various games with intermediate numbers of tower kills.\n",
    "\n",
    "### Inhibitor Kills\n",
    "The distribution of inhibitor kills in games is as follows:\n",
    "- **Majority**: Most games have 0 inhibitor kills.\n",
    "- **Second Highest**: Values of 1 or 2 are relatively common.\n",
    "- **Less Frequent**: Inhibitor kills from 3 and above are less common, with a maximum of 6.\n",
    "\n",
    "### Baron Kills\n",
    "The distribution of Baron kills in games is:\n",
    "- **Most Common**: 0 Baron kills.\n",
    "- **Near Half**: 1 Baron kill.\n",
    "- **Maximum**: The highest observed value is 2 Baron kills.\n",
    "\n",
    "### Dragon Kills\n",
    "The distribution of dragon kills is:\n",
    "- **Common Values**: 0, 1, or 2 dragon kills.\n",
    "- **Less Common**: 3 or 4 dragon kills.\n",
    "- **Maximum**: The highest value observed is 5 or 6 dragon kills, though these are rare.\n",
    "\n",
    "### Herald Kills\n",
    "The distribution of Herald kills shows:\n",
    "- **Most Common**: 0 Herald kills.\n",
    "- **Less Frequent**: Herald kills occur in approximately one-third of the games.\n",
    "\n",
    "## Team 2 Stats\n",
    "Team 2's statistics mirror those of Team 1, indicating a well-balanced dataset. In games, it's typical for the winning team to achieve more objectives, while the losing team secures fewer objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8295c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(integer_columns.columns):\n",
    "    # Print counts of each occurrence\n",
    "    value_counts = integer_columns[col].value_counts().sort_index()\n",
    "    for value, count in value_counts.items():\n",
    "        print(f\"{col} - Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6724f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for each column\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, col in enumerate(integer_columns.columns):\n",
    "    plt.subplot(5, 4, i + 1)  # Adjust subplot grid as per your number of columns\n",
    "    sns.boxplot(y=integer_columns[col])\n",
    "    plt.title(col)\n",
    "    plt.ylabel('Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ea845",
   "metadata": {},
   "source": [
    "A box plot, also known as a box-and-whisker plot, is a graphical representation of the distribution of numerical data through their quartiles. Here's how to interpret the components of a box plot:\n",
    "\n",
    "* **Box**: The box in the plot represents the interquartile range (IQR), which contains the middle 50% of the data. It is divided into two parts:\n",
    "\n",
    "* **Lower quartile (Q1)**: The bottom edge of the box represents the 25th percentile of the data. It marks the point below which 25% of the data fall.\n",
    "\n",
    "* **Upper quartile (Q3)**: The top edge of the box represents the 75th percentile of the data. It marks the point below which 75% of the data fall.\n",
    "\n",
    "* **Median (Q2)**: A line inside the box represents the median of the data, which is the 50th percentile. It divides the data into two halves, with 50% of the data points falling below it and 50% above it.\n",
    "\n",
    "* **Whiskers**: The whiskers extend from the edges of the box to show the range of the data outside the IQR.\n",
    "\n",
    "* **Lower whisker**: Typically extends to 1.5 times the IQR below Q1, or the minimum value within this range if no data points are further out (outliers).\n",
    "\n",
    "* **Upper whisker**: Extends to 1.5 times the IQR above Q3, or the maximum value within this range if no data points are further out.\n",
    "\n",
    "* **Outliers**: Individual data points that fall outside the whiskers are shown as individual points. They are potential anomalies in the data that differ significantly from other observations.\n",
    "\n",
    "* **Interpretation Tips**:\n",
    "Central Tendency: The median and the length of the box give you an idea about the central tendency and the spread of the data.\n",
    "Skewness: If the median is not in the center of the box, it indicates skewness in the data.\n",
    "Range and Variability: The length of the whiskers shows the range of the data, providing insights into the variability.\n",
    "Outliers: Points outside the whiskers are potential outliers that may warrant further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e44894",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = integer_columns.describe()\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb0431",
   "metadata": {},
   "source": [
    "## Analysis of Objective Kills in Game Dataset\n",
    "\n",
    "### Team 1 and Team 2 Objective Kills Comparison\n",
    "\n",
    "#### t1_towerKills and t2_towerKills:\n",
    "\n",
    "- **Similar Distributions**: Both teams exhibit similar distributions for tower kills.\n",
    "- **Mean Values**: Team 1 averages around 5.7 tower kills per game, while Team 2 averages 5.5, indicating teams typically destroy about 5-6 towers per game.\n",
    "- **Spread (Standard Deviation)**: Moderate spread suggests variability in tower destruction across different games.\n",
    "\n",
    "#### t1_inhibitorKills and t2_inhibitorKills:\n",
    "\n",
    "- **Less Common Objectives**: Inhibitor kills are less frequent compared to tower kills.\n",
    "- **Mean Values**: Both teams average approximately 1.0 inhibitor kill per game.\n",
    "- **Distribution**: Most games see teams securing 0 or 1 inhibitor per game, with some games reaching higher counts up to 10.\n",
    "\n",
    "#### t1_baronKills and t2_baronKills:\n",
    "\n",
    "- **Rare Objectives**: Baron kills are relatively rare compared to other objectives.\n",
    "- **Mean Values**: Team 1 and Team 2 each average around 0.4 Baron kills per game.\n",
    "- **Distribution**: Most games feature few or no Baron kills, with occasional games seeing up to 5 Baron captures.\n",
    "\n",
    "#### t1_dragonKills and t2_dragonKills:\n",
    "\n",
    "- **More Common than Barons**: Dragon kills occur more frequently than Baron kills.\n",
    "- **Mean Values**: Both teams average approximately 1.4 Dragon kills per game.\n",
    "- **Distribution**: Teams typically secure 0-2 Dragons per game, with some games achieving up to 6 Dragon kills.\n",
    "\n",
    "#### t1_riftHeraldKills and t2_riftHeraldKills:\n",
    "\n",
    "- **Least Common Objectives**: Rift Herald kills are the least frequent among all objectives.\n",
    "- **Mean Values**: Team 1 averages about 0.3 Rift Herald kills per game, while Team 2 averages 0.2.\n",
    "- **Distribution**: Most games do not include a Rift Herald kill, but when it occurs, it is usually once per game.\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Objective Control**: Teams prioritize tower destruction, followed by Dragon kills, with Barons and Rift Heralds being less common objectives.\n",
    "- **Game Dynamics**: The variability (standard deviation) in objective kills across games suggests varying levels of strategic focus on objectives.\n",
    "- **Comparative Analysis**: Both teams generally have balanced access to these objectives, with slight variations observed between the two teams in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4249c",
   "metadata": {},
   "source": [
    "# Champion picks and bans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f536526c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load champion information from JSON file\n",
    "with open('lol_ranked_dataset/champion_info.json', 'r') as f:\n",
    "    champion_info = json.load(f)\n",
    "    \n",
    "# Function to count occurrences and plot top champions with names\n",
    "def plot_top_champions(df, plot_title, champion_info):\n",
    "    # Concatenate all champion IDs from both teams\n",
    "    champ_cols = ['t1_champ1id', 't1_champ2id', 't1_champ3id', 't1_champ4id', 't1_champ5id', \n",
    "                  't2_champ1id', 't2_champ2id', 't2_champ3id', 't2_champ4id', 't2_champ5id']\n",
    "    all_champs = pd.concat([df[col] for col in champ_cols], ignore_index=True)\n",
    "    \n",
    "    # Count occurrences of each champion ID\n",
    "    champ_counts = all_champs.value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    # Get top 5 champions and their names\n",
    "    top_champs = champ_counts.head(10)\n",
    "    champ_ids = top_champs.index.astype(str)\n",
    "    champ_names = [champion_info['data'][champ]['name'] for champ in champ_ids]\n",
    "    \n",
    "    # Plotting the top 5 champions with names\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_champs.plot(kind='bar', color='skyblue')\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Champion Name')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(range(len(champ_names)), champ_names, rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot most banned champions with names\n",
    "def plot_most_banned_champions(df, plot_title, champion_info):\n",
    "    # Concatenate all ban columns from both teams\n",
    "    ban_cols = ['t1_ban1', 't1_ban2', 't1_ban3', 't1_ban4', 't1_ban5', \n",
    "                't2_ban1', 't2_ban2', 't2_ban3', 't2_ban4', 't2_ban5']\n",
    "    all_bans = pd.concat([df[col] for col in ban_cols], ignore_index=True)\n",
    "    \n",
    "    # Count occurrences of each ban ID\n",
    "    ban_counts = all_bans.value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    # Get top 5 most banned champions and their names\n",
    "    top_bans = ban_counts.head(10)\n",
    "    ban_ids = top_bans.index.astype(str)\n",
    "    ban_names = [champion_info['data'][ban]['name'] for ban in ban_ids]\n",
    "    \n",
    "    # Plotting the top 5 most banned champions with names\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_bans.plot(kind='bar', color='salmon')\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Champion Name')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(range(len(ban_names)), ban_names, rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting top champions picked across both teams with names\n",
    "plot_top_champions(df, 'Top Champions Picked', champion_info)\n",
    "\n",
    "# Plotting most banned champions across both teams with names\n",
    "plot_most_banned_champions(df, 'Most Banned Champions', champion_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d19cb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count occurrences and plot top champions with names using matplotlib pie chart\n",
    "def plot_top_champions_pie(df, plot_title, champion_info, min_percentage=1.3):\n",
    "    # Concatenate all champion IDs from both teams\n",
    "    champ_cols = ['t1_champ1id', 't1_champ2id', 't1_champ3id', 't1_champ4id', 't1_champ5id', \n",
    "                  't2_champ1id', 't2_champ2id', 't2_champ3id', 't2_champ4id', 't2_champ5id']\n",
    "    all_champs = pd.concat([df[col] for col in champ_cols], ignore_index=True)\n",
    "    \n",
    "    # Count occurrences of each champion ID\n",
    "    champ_counts = all_champs.value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    # Get top champions and their names\n",
    "    total_picks = champ_counts.sum()\n",
    "    champ_ids = champ_counts.index.astype(str)\n",
    "    champ_freq = champ_counts.values / total_picks * 100\n",
    "    \n",
    "    # Plotting the champions with names using matplotlib pie chart\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    patches, texts, autotexts = plt.pie(champ_freq, labels=None, startangle=140, autopct='%1.1f%%')\n",
    "    plt.title(plot_title)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    \n",
    "    # Adding labels only for champions with frequency > min_percentage\n",
    "    for i, (champ_id, freq) in enumerate(zip(champ_ids, champ_freq)):\n",
    "        champ_name = champion_info['data'][champ_id]['name']\n",
    "        if freq > min_percentage:\n",
    "            texts[i].set_text(f'{champ_name}')\n",
    "        else:\n",
    "            texts[i].set_text('')\n",
    "            autotexts[i].set_text('')  # Remove percentage text\n",
    "            autotexts[i].set_color('white')  # Set text color to match background\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with your DataFrame and champion_info JSON\n",
    "plot_top_champions_pie(df, 'Top Champions Picked (Min Percentage 1.3%)', champion_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d6dd3",
   "metadata": {},
   "source": [
    "As observed, the most frequently picked champions were Thresh and Tristana, with Vayne closely following. As the percentages decrease, they become increasingly similar, indicating that these champions are chosen at similar frequencies. However, it's important to note that certain champions are banned more frequently than others. Therefore, relying solely on pick rate from this plot may not provide a completely accurate measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9125f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot most banned champions with names using matplotlib pie chart\n",
    "def plot_most_banned_champions_pie(df, plot_title, champion_info, min_percentage=1.3):\n",
    "    # Concatenate all ban columns from both teams\n",
    "    ban_cols = ['t1_ban1', 't1_ban2', 't1_ban3', 't1_ban4', 't1_ban5', \n",
    "                't2_ban1', 't2_ban2', 't2_ban3', 't2_ban4', 't2_ban5']\n",
    "    all_bans = pd.concat([df[col] for col in ban_cols], ignore_index=True)\n",
    "    \n",
    "    # Count occurrences of each ban ID\n",
    "    ban_counts = all_bans.value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    # Get top banned champions and their names\n",
    "    total_bans = ban_counts.sum()\n",
    "    ban_ids = ban_counts.index.astype(str)\n",
    "    ban_freq = ban_counts.values / total_bans * 100\n",
    "    \n",
    "    # Plotting the banned champions with names using matplotlib pie chart\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    patches, texts, autotexts = plt.pie(ban_freq, labels=None, startangle=140, autopct='%1.1f%%')\n",
    "    plt.title(plot_title)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    \n",
    "    # Adding labels only for banned champions with frequency > min_percentage\n",
    "    for i, (ban_id, freq) in enumerate(zip(ban_ids, ban_freq)):\n",
    "        if ban_id == '-1':  # Check if ban_id is '-1'\n",
    "            texts[i].set_text('')\n",
    "            autotexts[i].set_text('')\n",
    "            autotexts[i].set_color('white')\n",
    "            continue  # Skip to the next iteration\n",
    "        \n",
    "        champ_name = champion_info['data'][ban_id]['name']\n",
    "        if freq > min_percentage:\n",
    "            texts[i].set_text(f'{champ_name}')\n",
    "        else:\n",
    "            texts[i].set_text('')\n",
    "            autotexts[i].set_text('')  # Remove percentage text\n",
    "            autotexts[i].set_color('white')  # Set text color to match background\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with your DataFrame and champion_info JSON\n",
    "plot_most_banned_champions_pie(df, 'Most Banned Champions (Min Percentage 1.3%)', champion_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3707f2",
   "metadata": {},
   "source": [
    "Yasuo stands out as the most banned champion by a significant margin. This could be attributed to his high mobility and steep learning curve, allowing players to execute complex and impressive plays that draw attention. The more popular a champion becomes, the more players of varying skill levels may attempt to use them, which can lead to both skilled and less experienced players wanting to ban this champion. Similar trends can be observed with champions like Zed and Draven. Unlike the pick rate chart, where champions are more evenly distributed, the ban pie chart reveals a more concentrated focus. This indicates a widespread consensus among players on which champions are considered ban-worthy. Riot with this plot, can try to understand why this happens and why this same champions tend to be banned, this could be because the champions is overall overpowered in a given patch or simply annoying to play with or against. Despite high ban rates, champions such as Tristana, Twitch, Kayn, and Vayne continue to maintain high pick rates, indicating strong player demand for these champions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c7bf66",
   "metadata": {},
   "source": [
    "# Champion win rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef3f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to calculate win rates for champions\n",
    "def calculate_win_rates(df):\n",
    "    # Initialize dictionaries to store games played and wins for each champion\n",
    "    champion_games = {}\n",
    "    champion_wins = {}\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Determine the winning team and champions\n",
    "        winning_team = int(row['winner'])\n",
    "        team1_champions = [row[f't1_champ{i}id'] for i in range(1, 6)]\n",
    "        team2_champions = [row[f't2_champ{i}id'] for i in range(1, 6)]\n",
    "        \n",
    "        # Update games played for each champion in team 1\n",
    "        for champ_id in team1_champions:\n",
    "            if champ_id not in champion_games:\n",
    "                champion_games[champ_id] = 0\n",
    "                champion_wins[champ_id] = 0\n",
    "            champion_games[champ_id] += 1\n",
    "            if winning_team == 1:\n",
    "                champion_wins[champ_id] += 1\n",
    "        \n",
    "        # Update games played for each champion in team 2\n",
    "        for champ_id in team2_champions:\n",
    "            if champ_id not in champion_games:\n",
    "                champion_games[champ_id] = 0\n",
    "                champion_wins[champ_id] = 0\n",
    "            champion_games[champ_id] += 1\n",
    "            if winning_team == 2:\n",
    "                champion_wins[champ_id] += 1\n",
    "    \n",
    "    # Calculate win rates for each champion\n",
    "    champion_win_rates = {}\n",
    "    for champ_id in champion_games:\n",
    "        if champion_games[champ_id] > 0:\n",
    "            win_rate = champion_wins[champ_id] / champion_games[champ_id]\n",
    "            champion_win_rates[champ_id] = win_rate\n",
    "    \n",
    "    return champion_win_rates\n",
    "\n",
    "# Calculate win rates for champions\n",
    "champion_win_rates = calculate_win_rates(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9be938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract win rates into a list\n",
    "win_rates = list(champion_win_rates.values())\n",
    "\n",
    "# Get the min and max win rates\n",
    "min_win_rate = min(win_rates) - 0.001\n",
    "max_win_rate = max(win_rates) + 0.001\n",
    "\n",
    "# Create a density plot using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(win_rates, fill=True)\n",
    "plt.title('Density Plot of Champion Win Rates')\n",
    "plt.xlabel('Win Rate')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add vertical lines for 45%, 55%, and mean\n",
    "plt.axvline(0.47, linestyle='dotted', color='red', label='47% Win Rate')\n",
    "plt.axvline(0.53, linestyle='dotted', color='green', label='53% Win Rate')\n",
    "\n",
    "# Calculate and add a vertical line for the mean win rate\n",
    "mean_win_rate = sum(win_rates) / len(win_rates)\n",
    "plt.axvline(mean_win_rate, linestyle='dashed', color='blue', label=f'Mean Win Rate ({mean_win_rate:.3f})')\n",
    "\n",
    "# Print top 5 champions with highest win rates\n",
    "sorted_champions = sorted(champion_win_rates.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 5 champions with highest win rates:\")\n",
    "for i, (champ, win_rate) in enumerate(sorted_champions[:10], start=1):\n",
    "    print(f\"{i}. Champion '{champion_info['data'][champ]['name']}' (ID: {champ}): Win Rate = {win_rate:.2%}\")\n",
    "\n",
    "# Print top 5 champions with lowest win rates\n",
    "print(\"\\nTop 5 champions with lowest win rates:\")\n",
    "for i, (champ, win_rate) in enumerate(sorted_champions[-10:], start=1):\n",
    "    print(f\"{i}. Champion '{champion_info['data'][champ]['name']}' (ID: {champ}): Win Rate = {win_rate:.2%}\")\n",
    "    \n",
    "\n",
    "# Set x-axis limits to show only the range of min and max win rates\n",
    "plt.xlim(min_win_rate, max_win_rate)\n",
    "\n",
    "plt.legend()  # Show legend with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc36631",
   "metadata": {},
   "source": [
    "With this plot, we can analyze the health of gameplay by assessing which champions are winning frequently and which are struggling. In an ideal scenario, all champions would ideally have win rates around 50%, indicating a balanced state where victories and losses are evenly distributed. For example, Ryze has a win rate of 40.79%, suggesting that out of every 10 games, Ryze players lose about 6. In contrast, Janna boasts a 55.53% win rate. Janna's high win rate reflects her strength, which likely contributes to her popularity among players, as seen on the champion picks plot.\n",
    "\n",
    "Riot Games can use win rate data to identify champions in need of adjustments, whether by buffing those with low win rates or addressing balance issues among high-win-rate champions. However, win rates despite being a strong indicator of champion problems, they alone can't say for certain that is the truth.For example, new champions often start with lower win rates due to players' unfamiliarity and learning curve, which is natural as players adapt. This learning curve can also affect older champions with complex kits, where less skilled players might struggle more, resulting in lower win rates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfb53b",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08922253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the target variable 'Winner'\n",
    "X = df.drop(columns=['winner'])\n",
    "\n",
    "# Step 2: Define your target (y)\n",
    "y = df['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d5c4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33333, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "667bbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit on training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform training, validation, and test sets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "'''\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform training, validation, and test sets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled  = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Print the shape of each set\n",
    "print(f\"Training set shape: {X_train_scaled .shape}, {y_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val_scaled .shape}, {y_val.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled .shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702b7da",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cee3be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = logreg.predict(X_val_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Accuracy on validation set: {accuracy:.6f}')\n",
    "\n",
    "# Classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Plot confusion matrix with seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False,\n",
    "            xticklabels=['Team 1 Wins', 'Team 2 Wins'],\n",
    "            yticklabels=['Team 1 Wins', 'Team 2 Wins'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e42364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = best_dt_model.predict(X_val)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_val, y_val)\n",
    "print(f'Accuracy on validation set: {accuracy:.6f}')\n",
    "\n",
    "# Print best model parameters\n",
    "print(f'\\nBest model parameters found in GridSearchCV:')\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_val, y_val))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_val, y_val)\n",
    "\n",
    "# Plot confusion matrix with seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False,\n",
    "            xticklabels=['Team 1 Wins', 'Team 2 Wins'],\n",
    "            yticklabels=['Team 1 Wins', 'Team 2 Wins'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60dbda",
   "metadata": {},
   "source": [
    "# Permutation Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86ebbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    logreg, X_test_scaled, y_test, n_repeats=10, random_state=42,\n",
    ")\n",
    "\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=X.columns[sorted_importances_idx],\n",
    ")\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "376c1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate permutation importance\n",
    "result = permutation_importance(\n",
    "    logreg, X_test_scaled, y_test, n_repeats=10, random_state=42,\n",
    ")\n",
    "\n",
    "# Sort importances\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "\n",
    "# Select top and bottom 5 columns\n",
    "selected_idx = list(sorted_importances_idx[:10]) + list(sorted_importances_idx[-10:])\n",
    "selected_importances = result.importances[selected_idx]\n",
    "\n",
    "# Create a DataFrame for the selected importances\n",
    "importances = pd.DataFrame(\n",
    "    selected_importances.T,\n",
    "    columns=X.columns[selected_idx],\n",
    ")\n",
    "\n",
    "# Plot the boxplot\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = importances.plot.box(vert=False, whis=10, patch_artist=True)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "\n",
    "# Add a horizontal line to separate top 5 and bottom 5 features\n",
    "num_top_features = 9\n",
    "num_total_features = len(selected_idx)\n",
    "ax.axhline(y=num_total_features - num_top_features - 0.5, color='r', linestyle='-', linewidth=2)\n",
    "\n",
    "ax.figure.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2667b5a",
   "metadata": {},
   "source": [
    "To determine which features contributed most to the model's predictions, permutation feature importance was used. This method involves shuffling the values of each feature to observe the change in model accuracy. If the accuracy decreases significantly when a feature's values are shuffled, it indicates that the feature is important for the model.\n",
    "\n",
    "The plot above demonstrates that features like **tower kills, baron kills, first tower, and inhibitor kills** are extremely important, with **tower kills for each team being particularly significant**. Conversely, features such as **game duration, the first dragon and herald, and the number of dragon and herald kills are considered less important**. In some cases, shuffling these less important features even resulted in an increase in model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409294f",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "124947f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the feature names are retained\n",
    "feature_names = df.drop(columns=['winner']).columns\n",
    "\n",
    "# Initialize and use the SHAP explainer with the actual feature names\n",
    "explainer = shap.Explainer(logreg, X_train_scaled, feature_names=feature_names)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer(X_test_scaled)\n",
    "\n",
    "# Plot the SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_test_scaled, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624b5e1",
   "metadata": {},
   "source": [
    "In both the permutation feature importance plot and the SHAP (SHapley Additive exPlanations) values analysis, features like \"tower kills,\" \"first tower,\" and \"inhibitor kills\" emerged as the most significant predictors. When using SHAP values for interpretability, lower values indicate contributions towards class 0 (indicating a win for team 1), while higher values indicate contributions towards class 1 (indicating a win for team 2).\n",
    "\n",
    "To illustrate this, let's examine the top two features: `t2_towerKills` and `t1_towerKills`. For `t2_towerKills`, higher feature values (represented by a red color in the plot) correspond to higher SHAP values. This makes sense because the more towers team 2 destroys, the greater their chances of winning. Conversely, for `t1_towerKills`, higher feature values (also marked in red) lead to lower SHAP values. This indicates that as team 1 destroys more towers, the likelihood of team 1 winning increases, while the likelihood of team 2 winning decreases. \n",
    "\n",
    "**In summary, high values for team 2 tower kills boost team 2's chances, while high values for team 1 tower kills boost team 1's chances.**\n",
    "\n",
    "Below there's an example for three games, that shows how much each feature contributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb33e56",
   "metadata": {},
   "source": [
    "# Game 1 (Complete Victory of Team 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d345a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the SHAP values for a single prediction\n",
    "# Example: for the first instance in the validation set\n",
    "shap.force_plot(explainer.expected_value, shap_values.values[0], X_test_scaled[0], feature_names=feature_names, matplotlib=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10de96",
   "metadata": {},
   "source": [
    "**Important features mentioned:**\n",
    "- **`t2_towerKills`:** 3\n",
    "- **`t1_towerKills`:** 10\n",
    "- **`t1_baronKills`:** 2\n",
    "- **`winner`:** 1\n",
    "\n",
    "**Base Value:**  \n",
    "The base value, positioned around the 0 mark, represents the average model prediction when no specific feature values are considered.\n",
    "\n",
    "**Final Prediction \\( f(x) \\):**  \n",
    "The model's prediction for this instance is approximately \\(-11.27\\), shown at the center of the plot. This negative value suggests a stronger prediction towards one class, team 1.\n",
    "\n",
    "**Feature Contributions:**  \n",
    "- **`FirstTower`:** This feature has a negative SHAP value of approximately \\(-0.83\\), shown in red. It decreases the final prediction, pushing it towards class 0 (potentially indicating a win for team 1).\n",
    "- **`t2_towerKills`:** With a significant negative SHAP value of approximately \\(-1.44\\), this feature strongly pushes the prediction towards a negative outcome, suggesting a lower likelihood of team 1 winning.\n",
    "- **`t1_towerKills`:** This feature contributes positively, with a SHAP value of around \\(0.87\\), indicating that more tower kills by team 1 (9) are increasing the likelihood of a win for team 2.\n",
    "- **`t1_baronKills`:** Also contributing positively, with a SHAP value of around \\(1.08\\), this feature suggests that more baron kills are associated with a higher likelihood of team 2 winning.\n",
    "\n",
    "**Interpretation:**  \n",
    "- **Negative SHAP values:** Features like `t2_towerKills` and `firstTower` decrease the model's prediction value, pushing it towards class 0 (potentially indicating a win for team 1).\n",
    "- **Positive SHAP values:** Features like `t1_towerKills` and `baronKills` increase the model's prediction value, pushing it towards class 1 (potentially indicating a win for team 2).\n",
    "\n",
    "**Conclusion:**  \n",
    "The final prediction of \\(-11.27\\) suggests a strong influence from features with negative SHAP values, primarily `t2_towerKills` and `firstTower`. This outcome indicates that, for this instance, the model predicts an outcome favoring class 0, potentially a win for team 1. The force plot clearly shows how each feature supports or opposes the final prediction, providing insights into the model's decision-making process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfdda6",
   "metadata": {},
   "source": [
    "# Game 2 (Complete Victory of Team 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0ce0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: for the first instance in the validation set\n",
    "shap.force_plot(explainer.expected_value, shap_values.values[1], X_test_scaled[1], feature_names=feature_names, matplotlib=True)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48481f34",
   "metadata": {},
   "source": [
    "**Important Features mentioned:**\n",
    "\n",
    "- **`t1_towerKills:`** 1\n",
    "- **`t2_towerKills:`** 9\n",
    "- **`t1_riftHeraldKills:`** 1\n",
    "- **`FirstTower:`** 2\n",
    "- **`winner`:** 2\n",
    "    \n",
    "**Base Value:**  \n",
    "The base value, positioned around the 0 mark, represents the average model prediction when no specific feature values are considered.\n",
    "\n",
    "**Final Prediction \\( f(x) \\):**:\n",
    "The model's prediction for this instance is approximately 9.65, as shown at the center of the plot. This positive value suggests a stronger prediction towards one class, potentially indicating an outcome favoring one of the teams, which is identified as Team 2 based on the features and SHAP values.\n",
    "\n",
    "**Feature Contributions:**  \n",
    "- **`t1_towerKills:`** Despite being a typically positive feature, here it has a negative SHAP value (around -1.23), indicating that fewer tower kills (1) by Team 1 reduce the likelihood of their win, thus favoring Team 2.\n",
    "\n",
    "- **`t2_towerKills:`** Team 2 tower kills (9) is associated with a positive SHAP value (around 0.89), suggesting it contributes to a higher likelihood of Team 2 winning.\n",
    "\n",
    "- **`t1_riftHeraldKills:`** This feature has a significant positive SHAP value (around 1.73), indicating that the Rift Herald kill by Team 1 pushed the prediction towards a positive outcome, potentially indicating a win for Team 2.\n",
    "\n",
    "- **`FirstTower:`** The first tower kill is linked with a positive SHAP value (around 1.01), showing it as a significant factor contributing to the positive prediction towards Team 2's victory.\n",
    "\n",
    "- **`Winner Prediction:`**\n",
    "The final prediction of 9.65 indicates a strong leaning towards Team 2 as the winner. The positive SHAP contributions, particularly from t1_riftHeraldKills and FirstTower, significantly influence this outcome.\n",
    "\n",
    "**Interpretation:**\n",
    "- **Positive SHAP values:** The significant positive contributions from `t1_riftHeraldKills`, `t2_towerKills`, and `FirstTower` increase the model's prediction value, indicating a strong likelihood of a win for Team 2.\n",
    "\n",
    "- **Negative SHAP values:** The negative contribution from `t1_towerKills` suggests that the model slightly accounts for fewer tower kills by Team 1, but this is not enough to offset the strong positive influences.\n",
    "\n",
    "**Conclusion:**\n",
    "The model's final prediction of 9.65, along with the SHAP values, indicates a clear prediction favoring Team 2 as the winner. The positive contributions from features like `t1_riftHeraldKills` and `t2_towerKills` significantly drive this prediction, outweighing any negative impact from the other features. The SHAP force plot effectively shows how each feature influences the final prediction, providing clear insights into the model's reasoning for this specific game instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb529f",
   "metadata": {},
   "source": [
    "# Game 3 (Very competitive game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e823b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: for the first instance in the validation set\n",
    "shap.force_plot(explainer.expected_value, shap_values.values[5], X_test_scaled[5], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36554d40",
   "metadata": {},
   "source": [
    "**Important Features Mentioned:**\n",
    "\n",
    "- **`gameDuration:`** 2302 seconds\n",
    "- **`t1_riftHeraldKills:`** 1\n",
    "- **`firstTower:`** 1\n",
    "- **`t2_baronKills:`** 2\n",
    "- **`t2_towerKills:`** 8\n",
    "- **`t1_towerKills:`** 7\n",
    "- **`t1_baronKills:`** 1\n",
    "- **`firstInhibitor:`** 2\n",
    "- **`firstDragon:`** 1\n",
    "- **`winner:`** 1 (Team 1)\n",
    "\n",
    "**Base Value:**  \n",
    "The base value represents the average model prediction when no specific feature values are considered, positioned around the 0 mark.\n",
    "\n",
    "**Final Prediction \\( f(x) \\):**  \n",
    "The model's prediction for this instance is approximately 1.87. Since the prediction is a positive value, it suggests that the model favors Team 2 to win based on the features and SHAP values.\n",
    "\n",
    "**Feature Contributions:**\n",
    "\n",
    "- **`gameDuration:`** The SHAP value of 0.9174 indicates a positive contribution from a game duration of 2302 seconds. Longer games tend to favor the team that performs well in the later stages, which benefits Team 2 in this case.\n",
    "\n",
    "- **`t1_riftHeraldKills:`** The SHAP value of 1.732 for Team 1’s Rift Herald kill (1) suggests a positive impact, contributing towards Team 2’s likelihood of winning. This indicates that while beneficial, the Rift Herald kill's impact is outweighed by other features favoring Team 2.\n",
    "\n",
    "- **`firstTower:`** The SHAP value of -0.8304 shows a negative contribution from Team 1’s first tower kill, suggesting that securing the first tower benefitted them.\n",
    "\n",
    "- **`t2_baronKills:`** The SHAP value of 2.587 indicates a strong positive contribution from Team 2’s Baron kills (2). This feature significantly boosts the prediction for Team 2, highlighting the importance of this objective for their victory.\n",
    "\n",
    "- **`t2_towerKills:`** With a SHAP value of 0.6327, Team 2’s 8 tower kills positively contribute to the prediction. More tower kills generally strengthen Team 2’s position, favoring their chances of winning.\n",
    "\n",
    "- **`t1_towerKills:`** The SHAP value of 0.3435 for Team 1’s 7 tower kills indicates a small positive contribution. This suggests that Team 1’s number of tower kills actually favors Team 2’s chances of winning. This counterintuitive result may be due to the fact that in many games, a team that destroys fewer towers (even if they have more kills) often ends up losing, thereby improving the odds for Team 2.\n",
    "\n",
    "- **`t1_baronKills:`** The SHAP value of 1.081 for Team 1’s Baron kill (1) indicates a positive contribution. Despite the fact that securing the Baron is typically a significant advantage for a team, the positive SHAP value here suggests that this feature actually favors Team 2’s chances of winning. This is likely because Team 1’s fewer Baron kills compared to Team 2 may diminish their overall advantage, thus improving Team 2's predicted chances of victory.\n",
    "\n",
    "- **`firstInhibitor:`** The SHAP value of 1.022 reflects a positive contribution from securing the first inhibitor (2). This milestone generally benefits the team achieving it, thus favoring Team 2’s prediction.\n",
    "\n",
    "- **`firstDragon:`** With a SHAP value of -0.7823, Team 1’s first dragon kill (1) has a negative contribution. This suggests that securing the first dragon benefits Team 1, but the effect is not as strong as features.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- **Positive SHAP Values:** Features such as `t2_baronKills`, `t2_towerKills`, `t1_riftHeraldKills`, and `firstInhibitor` have significant positive contributions, driving the model’s prediction towards Team 2’s victory.\n",
    "\n",
    "- **Negative SHAP Values:** The negative contributions from `firstTower` and `firstDragon` suggest that these features actually help Team 1’s chances of winning, despite their typical advantage for Team 2.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "The final prediction of 1.87, supported by the SHAP values, suggests a favorable outcome for Team 2. The significant positive contributions from features like `t2_baronKills`, `t1_riftHeraldKills`, and `t2_towerKills` indicate that Team 2 was more likely to win according to the model. The SHAP values offer clear insights into how each feature impacts the prediction, underscoring the factors that contribute to Team 2's projected victory.\n",
    "\n",
    "However, despite this prediction, Team 1 emerged as the actual winner of the game. Analyzing the feature contributions reveals potential reasons for this discrepancy. Although Team 2 secured more objectives such as towers and Barons, they ultimately lost, possibly due to critical late-game mistakes or superior scaling of Team 1's champions. This insight highlights the complexity of game outcomes, where individual objectives and their contributions may not always align with the final result.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_3",
   "language": "python",
   "name": "py310_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
